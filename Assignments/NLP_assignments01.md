1. Explain One-Hot Encoding

   To keep it simple it is like assigning categorical value ot the binary (encoded) vaules. It depends upon the no.of categorical variables.numbers are replaced by 1s and 0s. Depending on which column has what value.
   

2. Explain Bag of Words

   Bag of words is a Natural Language Processing technique of text modelling. In technical terms, we can say that it is a method of feature extraction with text data. This approach is a simple and flexible way of extracting features from documents.  
  
  
3. Explain Bag of N-Grams

   
4. Explain TF-IDF

   
5. What is OOV problem?

   
6. What are word embeddings?

   
7. Explain Continuous bag of words (CBOW)

   
8. Explain SkipGram

   
9. Explain Glove Embeddings.

   
